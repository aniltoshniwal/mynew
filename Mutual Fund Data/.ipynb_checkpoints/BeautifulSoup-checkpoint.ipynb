{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "NoData=[]\n",
    "urls=pd.read_csv('MutualFundLinks.csv')\n",
    "count=1\n",
    "for url in urls['links']:\n",
    "#url=input('Enter URL or Paste here: ')\n",
    "    page=requests.get(url).text\n",
    "    soup=BeautifulSoup(page,'html.parser')\n",
    "    \n",
    "####################################---EQUITY--##################################################\n",
    "    data=soup.find('table',{'class':'fund-snapshot-port-holdings-equity'})\n",
    "    try:\n",
    "        file_name = soup.title.text.split(soup.title.text[soup.title.text.index(':'):])[0].rstrip()\n",
    "    except:\n",
    "        file_name = soup.title.text.split(soup.title.text[soup.title.text.index('-'):])[0].rstrip()\n",
    "    #file_name = soup.title.text.split(soup.title.text[soup.title.text.index(':'):])[0].rstrip()\n",
    "    table=[]\n",
    "    col_name=[]\n",
    "    if data is not None:\n",
    "        for rows in data.find_all('tr'):\n",
    "            cols=rows.find_all('td')\n",
    "            if len(cols)>=6:\n",
    "                dat=[]\n",
    "                table.append(dat)\n",
    "                for i in range(len(cols)):\n",
    "                    if i==0:\n",
    "                        continue\n",
    "                    dat.append(cols[i].text.strip())\n",
    "        for th in data.find_all('tr'):\n",
    "            name=th.find_all('th')\n",
    "            if len(name)==7:\n",
    "                for i in range(len(name)):\n",
    "                    if i==0:\n",
    "                        continue            \n",
    "                    col_name.append(name[i].text.strip())\n",
    "        df=pd.DataFrame(table, columns=col_name)\n",
    "        df.to_csv(str(count)+file_name+'Equity.csv')\n",
    "##########################################---HYBRID---###########################################\n",
    "\n",
    "    data1=soup.find('table',{'class':'fund-snapshot-port-holdings-other'})\n",
    "    #file_name = soup.title.text.split(soup.title.text[soup.title.text.index(':'):])[0].rstrip()\n",
    "    tableH=[]\n",
    "    col_nameH=[]\n",
    "    if data1 is not None:\n",
    "        for rows in data1.find_all('tr'):\n",
    "            cols=rows.find_all('td')\n",
    "            if len(cols)>=6:\n",
    "                dat=[]\n",
    "                tableH.append(dat)\n",
    "                for i in range(len(cols)):\n",
    "                    if i==0:\n",
    "                        continue\n",
    "                    dat.append(cols[i].text.strip())\n",
    "        for th in data1.find_all('tr'):\n",
    "            name=th.find_all('th')\n",
    "            if len(name)==6:\n",
    "                for i in range(len(name)):\n",
    "                    if i==0:\n",
    "                        continue            \n",
    "                    col_nameH.append(name[i].text.strip())\n",
    "        if data is None:\n",
    "            df1=pd.DataFrame(tableH, columns=col_nameH)\n",
    "            df1.to_csv(file_name+'.csv')\n",
    "        else:\n",
    "            df1=pd.DataFrame(tableH, columns=col_nameH)\n",
    "            df1.to_csv(str(count)+file_name+'hybrid.csv')\n",
    "    else:\n",
    "        NoData.append(url)\n",
    "        print(f\"No mutual fund found in {file_name}\")\n",
    "    count+=1\n",
    "\n",
    "####################################################################################### \n",
    "df=pd.DataFrame(NoData, columns=[\"NoDataUrls\"])\n",
    "df.to_csv('NoDataUrls.csv')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url_all='https://www.valueresearchonline.com/funds/fundSelector/default.asp?myport=&amc=4%2C8799%2C5%2C312%2C332%2C8%2C181%2C339%2C8927%2C28%2C302%2C308%2C14%2C9023%2C298%2C9636%2C9655%2C319%2C12232%2C19%2C218%2C185%2C21%2C11141%2C327%2C9054%2C24%2C9055%2C10157%2C15%2C11%2C317%2C186%2C25%2C26%2C187%2C27%2C10%2C9521%2C311%2C12160&cat=equityAll%2CdebtsAll%2ChybridAll%2C100%2C101%2C102%2C103%2C104%2C105%2C106%2C107%2C108%2C109%2C110%2C111%2C112%2C113%2C114%2C115%2C116%2C117%2C118%2C119%2C120%2C121%2C122%2C123%2C124%2C125%2C126%2C127%2C128%2C129%2C130%2C131%2C132%2C133%2C134%2C135%2C136%2C137%2C139%2C140%2C141%2C142%2C143%2C144&exc=&isTabChng=1&pg=#'\n",
    "\n",
    "page=requests.get(url_all).text\n",
    "soup=BeautifulSoup(page,'html.parser')\n",
    "data=soup.find('div',{'class':'pull-left'})\n",
    "links=[]\n",
    "for rows in data.find_all('tr'):\n",
    "    cols=rows.find_all('td')\n",
    "    if len(cols)==9:\n",
    "        for i in cols:\n",
    "            c=i.find('a')\n",
    "            try:\n",
    "                if c.get('href')[0:4]!='/pdf':\n",
    "                    links.append('https://www.valueresearchonline.com'+c.get('href'))\n",
    "            except:\n",
    "\n",
    "                break\n",
    "df=pd.DataFrame(links,columns=['links'])\n",
    "df.to_csv('MutualFundLinks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = soup.title.text.split(soup.title.text[soup.title.text.index('-'):])[0].rstrip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url_all='https://www.valueresearchonline.com/funds/fundSelector/default.asp?myport=&amc=4%2C8799%2C5%2C312%2C332%2C8%2C181%2C339%2C8927%2C28%2C302%2C308%2C14%2C9023%2C298%2C9636%2C9655%2C319%2C12232%2C19%2C218%2C185%2C21%2C11141%2C327%2C9054%2C24%2C9055%2C10157%2C15%2C11%2C317%2C186%2C25%2C26%2C187%2C27%2C10%2C9521%2C311%2C12160&cat=equityAll%2CdebtsAll%2ChybridAll%2C100%2C101%2C102%2C103%2C104%2C105%2C106%2C107%2C108%2C109%2C110%2C111%2C112%2C113%2C114%2C115%2C116%2C117%2C118%2C119%2C120%2C121%2C122%2C123%2C124%2C125%2C126%2C127%2C128%2C129%2C130%2C131%2C132%2C133%2C134%2C135%2C136%2C137%2C139%2C140%2C141%2C142%2C143%2C144&exc=&isTabChng=1&pg=#'\n",
    "\n",
    "page=requests.get(url_all).text\n",
    "soup=BeautifulSoup(page,'html.parser')\n",
    "data=soup.find('div',{'class':'pull-left'})\n",
    "links=[]\n",
    "for rows in data.find_all('tr'):\n",
    "    cols=rows.find_all('td')\n",
    "    if len(cols)==9:\n",
    "        for i in cols:\n",
    "            c=i.find('a')\n",
    "            try:\n",
    "                if c.get('href')[0:4]!='/pdf':\n",
    "                    links.append('https://www.valueresearchonline.com'+c.get('href'))\n",
    "            except:\n",
    "\n",
    "                break\n",
    "df=pd.DataFrame(links,columns=['links'])\n",
    "df.to_csv('MutualFundLinks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\n",
    "print('Data Downloading Started.....')\n",
    "NoData = []  # In this list store NoData URLs\n",
    "table = []\n",
    "tableH = []\n",
    "#col_nameH = []\n",
    "#col_name = []\n",
    "urls = pd.read_csv('AllMutualFundPortfolioLinks.csv')  # Links file, 3952 in this file\n",
    "#url='https://www.valueresearchonline.com/funds/newsnapshot.asp?schemecode=7701'\n",
    "count = 1\n",
    "count1 = 1\n",
    "for url in urls['links']:\n",
    "    # create request for get data from url\n",
    "    page = requests.get(url).text\n",
    "    # parse data using BeautifulSoup for html view\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "    ############################################# ---EQUITY-- ###########################################################\n",
    "    # find the table in data using tag name and tag class name\n",
    "    data = soup.find('table', {'class': 'fund-snapshot-port-holdings-equity'})\n",
    "    try:\n",
    "        # Get the name of Mutual fund\n",
    "        file_name = soup.title.text.split(soup.title.text[soup.title.text.index(':'):])[0].rstrip()\n",
    "    except:\n",
    "        file_name = soup.title.text.split(soup.title.text[soup.title.text.index('-'):])[0].rstrip()\n",
    "    # file_name = soup.title.text.split(soup.title.text[soup.title.text.index(':'):])[0].rstrip()\n",
    "      # append table data in list for create DataFrame\n",
    "    col_name = []  # append columns name for DataFrame\n",
    "    if data is not None:\n",
    "        table.append([str(count)+'.'+file_name])\n",
    "        # find all table data row and columns\n",
    "        for rows in data.find_all('tr'):\n",
    "            cols = rows.find_all('td')\n",
    "            if len(cols) >= 6:\n",
    "                col = []\n",
    "                table.append(col)\n",
    "                for i in range(len(cols)):\n",
    "                    if i == 0:\n",
    "                        continue\n",
    "                    col.append(cols[i].text.strip())\n",
    "        if len(col_nameH)<=1:            \n",
    "            # find all columns name\n",
    "            for th in data.find_all('tr'):\n",
    "                name = th.find_all('th')\n",
    "                if len(name) == 7:\n",
    "                    for i in range(len(name)):\n",
    "                        if i == 0:\n",
    "                            continue\n",
    "                        col_name.append(name[i].text.strip())\n",
    "        count+=1 \n",
    "    ###############################################---HYBRID---#########################################################\n",
    "\n",
    "    data1 = soup.find('table', {'class': 'fund-snapshot-port-holdings-other'})\n",
    "    # file_name = soup.title.text.split(soup.title.text[soup.title.text.index(':'):])[0].rstrip()\n",
    "    #tableH = []\n",
    "    col_nameH = []\n",
    "    if data1 is not None:\n",
    "        tableH.append([str(count1)+'.'+file_name])\n",
    "        for rows in data1.find_all('tr'):\n",
    "            cols = rows.find_all('td')\n",
    "            if len(cols) >= 6:\n",
    "                dat = []\n",
    "                tableH.append(dat)\n",
    "                for i in range(len(cols)):\n",
    "                    if i == 0:\n",
    "                        continue\n",
    "                    dat.append(cols[i].text.strip())\n",
    "        if len(col_nameH)<=1:\n",
    "            for th in data1.find_all('tr'):\n",
    "                name = th.find_all('th')\n",
    "                if len(name) == 6:\n",
    "                    for i in range(len(name)):\n",
    "                        if i == 0:\n",
    "                            continue\n",
    "                        if dat:\n",
    "                            col_nameH.append(name[i].text.strip())\n",
    "        count1 += 1\n",
    "\n",
    "        if len(col)==0 and len(dat)==0:\n",
    "            NoData.append([url, file_name])  # Append NoData Urls\n",
    "        #print(f\"No mutual fund found in {file_name}\")\n",
    "    \n",
    "    \n",
    "if table:\n",
    "    # create DataFrame using Pandas\n",
    "    df = pd.DataFrame(table, columns=col_name)\n",
    "    # Save the Data file in csv format\n",
    "    df.to_csv(file_name + 'Equity.csv',index=False)\n",
    "\n",
    "\n",
    "if tableH:\n",
    "    df1 = pd.DataFrame(tableH, columns=col_nameH)\n",
    "    df1.to_csv(file_name + 'hybrid.csv',index=False)    \n",
    "\n",
    "df = pd.DataFrame(NoData, columns=[\"Urls\", \"Mutual_Fund_Name\"])\n",
    "df.to_csv('NoDataUrls.csv',index=False)\n",
    "#print(f\"{len(NoData)} blank URLs\")\n",
    "print('Completed')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if table:\n",
    "    # create DataFrame using Pandas\n",
    "    df = pd.DataFrame(table, columns=col_name)\n",
    "    # Save the Data file in csv format\n",
    "    df.to_csv('Equity.csv',index=False)\n",
    "\n",
    "\n",
    "if tableH:\n",
    "    df1 = pd.DataFrame(tableH, columns=col_nameH)\n",
    "    df1.to_csv('Hybrid or Debt.csv',index=False)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tableH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableH[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_nameH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = soup.find('table', {'class': 'fund-snapshot-port-holdings-other'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for th in data1.find_all('tr'):\n",
    "        name = th.find_all('th')\n",
    "        if len(name) == 6:\n",
    "            for i in range(len(name)):\n",
    "                if i == 0:\n",
    "                    continue\n",
    "                if dat:\n",
    "                    col_nameH.append(name[i].text.strip())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(url).text\n",
    "    # parse data using BeautifulSoup for html view\n",
    "soup = BeautifulSoup(page, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.valueresearchonline.com/funds/newsnapshot.asp?schemecode=2308'\n",
    "page = requests.get(url).text\n",
    "    # parse data using BeautifulSoup for html view\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "data = soup.find('table', {'class': 'fund-snapshot-port-holdings-equity'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tableH:\n",
    "    df1 = pd.DataFrame(tableH, columns=col_nameH)\n",
    "    df1.to_csv(file_name + 'hybrid.csv',index=False)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_nameH=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for th in data1.find_all('tr'):\n",
    "                name = th.find_all('th')\n",
    "                if len(name) == 6:\n",
    "                    for i in range(len(name)):\n",
    "                        if i == 0:\n",
    "                            continue\n",
    "                        if dat:\n",
    "                            col_nameH.append(name[i].text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for th in data.find_all('tr'):\n",
    "                name = th.find_all('th')\n",
    "                if len(name) == 7:\n",
    "                    for i in range(len(name)):\n",
    "                        if i == 0:\n",
    "                            continue\n",
    "                        col_name.append(name[i].text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "import time\n",
    "\n",
    "\n",
    "print('Data Downloading Started.....')\n",
    "NoData = []  # In this list store NoData URLs\n",
    "col_name = []\n",
    "col_nameH = []\n",
    "#url='https://www.valueresearchonline.com/funds/portfoliovr.asp?schemecode=15739'\n",
    "urls = pd.read_csv('AllMutualFundPortfolioLinks.csv')  # Links file, 3952 in this file\n",
    "count = 1\n",
    "count1 = 1\n",
    "for url in urls['links']:\n",
    "    # create request for get data from url\n",
    "    page = requests.get(url).text\n",
    "    # parse data using BeautifulSoup for html view\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "    ############################################# ---EQUITY-- ###########################################################\n",
    "    data = soup.find('table', {'class': 'fund-snapshot-port-holdings-equity'})\n",
    "    try:\n",
    "        # Get the name of Mutual fund\n",
    "        file_name = soup.title.text.split(soup.title.text[soup.title.text.index(':'):])[0].rstrip()\n",
    "    except:\n",
    "        file_name = soup.title.text.split(soup.title.text[soup.title.text.index('-'):])[0].rstrip()    \n",
    "    #table = []# append columns name for DataFrame\n",
    "    if data is not None:\n",
    "        if len(col_name)<=2:            \n",
    "            # find all columns name\n",
    "            for th in data.find_all('tr'):\n",
    "                name = th.find_all('th')\n",
    "                if len(name) == 7:\n",
    "                    for i in range(len(name)):\n",
    "                        if i == 0:\n",
    "                            continue\n",
    "                        col_name.append(name[i].text.strip())\n",
    "    try:\n",
    "        with open('EquityTest.csv', 'r') as readFile:\n",
    "            reader = csv.reader(readFile)\n",
    "            lines = list(reader)\n",
    "    except:\n",
    "        lines=str(1)\n",
    "    if len(lines[0])<=1 and len(col_name)>=5:\n",
    "\n",
    "        with open('EquityTest.csv', 'a') as csvFile:\n",
    "            writer = csv.writer(csvFile)\n",
    "            writer.writerow(col_name)\n",
    "        csvFile.close()\n",
    "    if data is not None:\n",
    "        tab=[str(count)+'.'+file_name]\n",
    "        with open('EquityTest.csv', 'a') as csvFile:\n",
    "            writer = csv.writer(csvFile)\n",
    "            writer.writerow(tab)\n",
    "        for rows in data.find_all('tr'):\n",
    "            cols = rows.find_all('td')\n",
    "            if len(cols) >= 6:\n",
    "                col = []\n",
    "                for i in range(len(cols)):\n",
    "                    if i == 0:\n",
    "                        continue\n",
    "                    col.append(cols[i].text.strip())\n",
    "                with open('EquityTest.csv', 'a') as csvFile:\n",
    "                    writer = csv.writer(csvFile)\n",
    "                    writer.writerow(col)\n",
    "        count+=1\n",
    "\n",
    "    ####################################----HYBRID-----##########################################################################\n",
    "    data1 = soup.find('table', {'class': 'fund-snapshot-port-holdings-other'})\n",
    "    if data1 is not None and len(col_nameH)<=1:\n",
    "        for th in data1.find_all('tr'):\n",
    "            name = th.find_all('th')\n",
    "            if len(name) == 6:\n",
    "                for i in range(len(name)):\n",
    "                    if i == 0:\n",
    "                        continue\n",
    "                    col_nameH.append(name[i].text.strip())\n",
    "    try:\n",
    "        with open('DebtTest.csv', 'r') as readFile:\n",
    "            reader = csv.reader(readFile)\n",
    "            line1 = list(reader)\n",
    "    except:\n",
    "        line1=str(1)\n",
    "    try:\n",
    "        with open('HybridTest.csv', 'r') as readFile:\n",
    "            reader = csv.reader(readFile)\n",
    "            line = list(reader)\n",
    "    except:\n",
    "        line=str(1)\n",
    "    \n",
    "    if len(line1[0])<=1 and len(col_nameH)>=5 and data1.th.text.split()[1]=='Debt':\n",
    "        with open('DebtTest.csv', 'a') as csvFile:\n",
    "            writer = csv.writer(csvFile)\n",
    "            writer.writerow(col_nameH)\n",
    "        csvFile.close()\n",
    "    if len(line[0])<=1 and len(col_nameH)>=5 and data1.th.text.split()[1]!='Debt':\n",
    "        with open('HybridTest.csv', 'a') as csvFile:\n",
    "            writer = csv.writer(csvFile)\n",
    "            writer.writerow(col_nameH)\n",
    "        csvFile.close()\n",
    "    try:\n",
    "        with open('HybridTest.csv', 'r') as readFile:\n",
    "            reader = csv.reader(readFile)\n",
    "            line = list(reader)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        with open('DebtTest.csv', 'r') as readFile:\n",
    "            reader = csv.reader(readFile)\n",
    "            line1 = list(reader)\n",
    "    except:\n",
    "        pass\n",
    "    if data1 is not None and len(line1[0])>=4 and len(data1)>=15:\n",
    "        tabH = [str(count1)+'.'+file_name]\n",
    "        if data1.th.text.split()[1]=='Debt':\n",
    "            with open('DebtTest.csv', 'a') as csvFile:\n",
    "                writer = csv.writer(csvFile)\n",
    "                writer.writerow(tabH)\n",
    "        else:\n",
    "            with open('HybridTest.csv', 'a') as csvFile:\n",
    "                writer = csv.writer(csvFile)\n",
    "                writer.writerow(tabH)\n",
    "        for rows in data1.find_all('tr'):\n",
    "            cols = rows.find_all('td')\n",
    "            if len(cols) >= 6:\n",
    "                dat = []\n",
    "                for i in range(len(cols)):\n",
    "                    if i == 0:\n",
    "                        continue\n",
    "                    dat.append(cols[i].text.strip())\n",
    "                if data1.th.text.split()[1]=='Debt':\n",
    "                    with open('DebtTest.csv', 'a') as csvFile:\n",
    "                        writer = csv.writer(csvFile)\n",
    "                        writer.writerow(dat)\n",
    "                elif data1.th.text.split()[1]!='Debt':\n",
    "                    with open('HybridTest.csv', 'a') as csvFile:\n",
    "                        writer = csv.writer(csvFile)\n",
    "                        writer.writerow(dat)\n",
    "        count1+=1\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "for i in range(5):\n",
    "    c\n",
    "    print(i,'second')\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.valueresearchonline.com/funds/portfoliovr.asp?schemecode=4018'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
