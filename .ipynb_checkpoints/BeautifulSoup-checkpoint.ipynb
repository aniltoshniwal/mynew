{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geocoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = geocoder.ip('14.143.74.69')\n",
    "g = geocoder.ip('me')\n",
    "print(g.latlng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.street"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.postal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data={'Noida':np.array(['Mr. A','Mr. B','Mr. C','Mr. D','Mr. E']),\n",
    "      'Moradabad':np.array(['Mr. F','Mr. G','Mr. H','Mr. I','Mr. J']),\n",
    "      'Rampur':np.array(['Mr. K','Mr. L','Mr. M','Mr. N','Mr. O']),\n",
    "    'Specialization':np.array(['Equities','Bonds','Mutual Fund','ETFS','Future & Options']),\n",
    "    'State':np.array(['Uttar Pradesh','Delhi','Haryana','Rajasthan','Bihar']),\n",
    "     'Uttar Pradesh':np.array(['Noida','Moradabad','Rampur']),\n",
    "      'Delhi':np.array(['Delhi NCR']),\n",
    "      'Haryana':np.array([]'Harrayana']),\n",
    "      'Rajasthan':np.array('Rajasthan')}\n",
    "\n",
    "data1=[['Mr. A','Mr. B','Mr. C','Mr. D','Mr. E'],['Mr. F','Mr. G','Mr. H','Mr. I','Mr. J'],\n",
    "['Mr. K','Mr. L','Mr. M','Mr. N','Mr. O'],['Equities','Bonds','Mutual Fund','ETFS','Future & Options'],\n",
    "['Uttar Pradesh','Delhi','Haryana','Rajasthan'],['Noida','Moradabad','Rampur'],'Delhi NCR','Haryana',\n",
    "'Rajasthan']\n",
    "col=['Noida','Moradabad','Rampur','Specialization','State','Uttar Pradesh','Delhi','Haryana','Rajasthan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#len(data1)\n",
    "#df.to_csv('data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(df['State'])):\n",
    "    print(f\"{i+1}.{df['State'][i]}\")\n",
    "s=int(input('Select State: '))\n",
    "\n",
    "for i in range(len(df[df['State'][s-1]])):\n",
    "  print(f\"{i+1}.{df[df['State'][s-1]][i]}\")\n",
    "k=int(input('Select City: '))\n",
    "print(f\"Selected city {df[df['State'][s-1]][k-1]}\")\n",
    "for i in range(len(df['Specialization'])):\n",
    "      print(f\"{i+1}.{df['Specialization'][i]}\")\n",
    "p=int(input('Select Specialization: '))\n",
    "#for i in range(len(df[df['State'][s-1]][k-1])):\n",
    "print(df[df[df['State'][s-1]][k-1]][p-1])\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=1\n",
    "for i in range(len(df[df['State'][s-1]])):\n",
    "              print(f\"{i+1}.{df[df['State'][s-1]][i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['State'][s-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['State'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data.csv',index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "from difflib import get_close_matches\n",
    "st=[]\n",
    "ct=[]\n",
    "class search_advisor():\n",
    "    def __init__(self):\n",
    "        data = json.loads(open('/home/am/python/Indian-States-And-Districts/states-and-districts.json').read())\n",
    "        state = input('Select state name: ').title()\n",
    "        f = [data['states'][i]['state'] for i in range(len(data['states']))]\n",
    "        self.data=data\n",
    "        self.state=state\n",
    "        self.f=f\n",
    "    def state_one(self):\n",
    "        global st\n",
    "        if self.state in self.f:\n",
    "            st = self.state\n",
    "            print(f'Selected State {st}')\n",
    "            return self.data, self.f\n",
    "        find_state = [i for i in get_close_matches(self.state, self.f)]\n",
    "        if len(find_state) == 1:\n",
    "\n",
    "            for i in find_state:\n",
    "                st = i\n",
    "                print(f'Selected State {st}')\n",
    "                return self.data, self.f\n",
    "\n",
    "\n",
    "        elif len(find_state) >= 2:\n",
    "            j = 1\n",
    "            state_more = []\n",
    "            for i in find_state:\n",
    "                print(f'{j}.{i}')\n",
    "                state_more.append(i)\n",
    "                j += 1\n",
    "            in_again = int(input('Choose any one: '))\n",
    "            if state_more[in_again - 1] in state_more:\n",
    "\n",
    "                st = state_more[in_again - 1]\n",
    "                print(f'Selected State {st}')\n",
    "                return st, self.data, self.f\n",
    "            else:\n",
    "                print('enter correct')\n",
    "\n",
    "        else:\n",
    "            print('State not found!')\n",
    "        raise SystemExit()\n",
    "    def city_one(self):\n",
    "        global st\n",
    "        print(st)\n",
    "        #st, data, f = state_one()\n",
    "        # print(st)\n",
    "        city = input('Select City name: ').title()\n",
    "        # for s in range(len(data['states'])):\n",
    "        find_city = [i for i in get_close_matches(city, self.data['states'][self.f.index(st)]['districts'])]\n",
    "        if city in data['states'][self.f.index(st)]['districts']:\n",
    "            ct = city\n",
    "            print(f'Selected City {ct}')\n",
    "            return ct\n",
    "        elif len(find_city) == 1:\n",
    "            for i in find_city:\n",
    "                ct = i\n",
    "                print(f'Selected City {ct}')\n",
    "                return ct\n",
    "        elif len(find_city) >= 2:\n",
    "\n",
    "            for i in find_city:\n",
    "                j = 1\n",
    "            city_more = []\n",
    "            for i in find_city:\n",
    "                print(f'{j}.{i}')\n",
    "                city_more.append(i)\n",
    "                j += 1\n",
    "            in_again = int(input('Choose any one: '))\n",
    "            if city_more[in_again - 1] in city_more:\n",
    "                ct = city_more[in_again - 1]\n",
    "                print(f'Selected City {ct}')\n",
    "                return ct,st\n",
    "            else:\n",
    "                print('enter correct')\n",
    "            # return st\n",
    "        else:\n",
    "            print('State not found!')\n",
    "            raise SystemExit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=search_advisor()\n",
    "a.city_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def city_one():\n",
    "        st, data, f = state_one()\n",
    "        # print(st)\n",
    "        city = input('Select City name: ').title()\n",
    "        # for s in range(len(data['states'])):\n",
    "        find_city = [i for i in get_close_matches(city, data['states'][f.index(st)]['districts'])]\n",
    "        if city in data['states'][f.index(st)]['districts']:\n",
    "            ct = city\n",
    "            print(f'Selected City {ct}')\n",
    "            return ct\n",
    "        elif len(find_city) == 1:\n",
    "            for i in find_city:\n",
    "                ct = i\n",
    "                print(f'Selected City {ct}')\n",
    "                return ct\n",
    "        elif len(find_city) >= 2:\n",
    "\n",
    "            for i in find_city:\n",
    "                j = 1\n",
    "            city_more = []\n",
    "            for i in find_city:\n",
    "                print(f'{j}.{i}')\n",
    "                city_more.append(i)\n",
    "                j += 1\n",
    "            in_again = int(input('Choose any one: '))\n",
    "            if city_more[in_again - 1] in city_more:\n",
    "                ct = city_more[in_again - 1]\n",
    "                print(f'Selected City {ct}')\n",
    "                return ct,st\n",
    "            else:\n",
    "                print('enter correct')\n",
    "            # return st\n",
    "        else:\n",
    "            print('State not found!')\n",
    "            raise SystemExit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=''\n",
    "b='New Delhi'\n",
    "print(a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list={'Delhi (NCT)':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "from difflib import get_close_matches\n",
    "data = json.loads(open('/home/am/python/Indian-States-And-Districts/states-and-districts.json').read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a={\"states\":[{\n",
    "    \"state\":\"Delhi (NCT)\",\n",
    "         \"districts\":[{  \n",
    "            \"Central Delhi\":['Equities', 'Bonds', 'Mutual Fund', 'ETFS', 'Future & Options']},\n",
    "            \"East Delhi\",\n",
    "            \"New Delhi\",\n",
    "            \"North Delhi\",\n",
    "            \"North East  Delhi\",\n",
    "            \"North West  Delhi\",\n",
    "            \"Shahdara\",\n",
    "            \"South Delhi\",\n",
    "            \"South East Delhi\",\n",
    "            \"South West  Delhi\",\n",
    "            \"West Delhi\"\n",
    "         ]}]\n",
    "      },"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import textract\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# This function will extract and return the pdf file text content.\n",
    "def extractPdfText(filePath=''):\n",
    "\n",
    "    # Open the pdf file in read binary mode.\n",
    "    fileObject = open(filePath, 'rb')\n",
    "\n",
    "    # Create a pdf reader .\n",
    "    pdfFileReader = PyPDF2.PdfFileReader(fileObject)\n",
    "\n",
    "    # Get total pdf page number.\n",
    "    totalPageNumber = pdfFileReader.numPages\n",
    "\n",
    "    # Print pdf total page number.\n",
    "    print('This pdf file contains totally ' + str(totalPageNumber) + ' pages.')\n",
    "\n",
    "    currentPageNumber = 0\n",
    "    text = ''\n",
    "\n",
    "    # Loop in all the pdf pages.\n",
    "    while(currentPageNumber < totalPageNumber ):\n",
    "\n",
    "        # Get the specified pdf page object.\n",
    "        pdfPage = pdfFileReader.getPage(currentPageNumber)\n",
    "\n",
    "        # Get pdf page text.\n",
    "        text = text + pdfPage.extractText()\n",
    "\n",
    "        # Process next page.\n",
    "        currentPageNumber += 1\n",
    "\n",
    "    if(text == ''):\n",
    "        # If can not extract text then use ocr lib to extract the scanned pdf file.\n",
    "        text = textract.process(filePath, method='tesseract', encoding='utf-8')\n",
    "       \n",
    "    return text\n",
    "\n",
    "# This function will remove all stop words and punctuations in the text and return a list of keywords.\n",
    "def extractKeywords(text):\n",
    "    # Split the text words into tokens\n",
    "    wordTokens = word_tokenize(text)\n",
    "\n",
    "    # Remove blow punctuation in the list.\n",
    "    punctuations = ['(',')',';',':','[',']',',']\n",
    "\n",
    "    # Get all stop words in english.\n",
    "    stopWords = stopwords.words('english')\n",
    "\n",
    "    # Below list comprehension will return only keywords tha are not in stop words and  punctuations\n",
    "    keywords = [word for word in wordTokens if not word in stopWords and not word in punctuations]\n",
    "   \n",
    "    return keywords\n",
    "\n",
    "if __name__ == '__main__': \n",
    "\n",
    "    pdfFilePath = '/home/am/Downloads/read.pdf'\n",
    "   \n",
    "    pdfText = extractPdfText(pdfFilePath)\n",
    "    print('There are ' + str(pdfText.__len__()) + ' word in the pdf file.')\n",
    "    #print(pdfText)\n",
    "    #print(pdfText)\n",
    "\n",
    "    keywords = extractKeywords(pdfText)\n",
    "    print('There are ' + str(keywords.__len__()) + ' keyword in the pdf file.')\n",
    "    #print(keywords) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfFilePath = '/home/am/Downloads/read.pdf'\n",
    "fileObject = open(pdfFilePath, 'rb')\n",
    "pdfFileReader = PyPDF2.PdfFileReader(fileObject)\n",
    "pdf=pdfFileReader.getPage(0) \n",
    "#print(pdf.extractText())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabula import read_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=read_pdf('/home/am/Downloads/read.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1=pd.DataFrame(df)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=read_pdf('/home/am/Downloads/read.pdf',multiple_tables=True)\n",
    "l=[]\n",
    "for i in df[1][10:13][0]:\n",
    "    l.append(i.split())\n",
    "    \n",
    "k=0\n",
    "for j in df[1][10:13][2]:\n",
    "    l[k].append(j)\n",
    "    k+=1\n",
    "k=0\n",
    "for m in df[1][10:13][4]:\n",
    "    l[k].append(m)\n",
    "    k+=1\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=read_pdf('/home/am/Downloads/read.pdf',multiple_tables=True,spreadsheet=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2=[]\n",
    "   \n",
    "for i in df[j][0]:\n",
    "        \n",
    "        l2.append(i.split('\\r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[1][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[1][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(df[1]['data'])):\n",
    "    for j in df[0]['data'][i]:\n",
    "        #print(j['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(len(df[1]['data'])):\n",
    "f=df[1]['data'][8][0]['text']\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[1]['data'][8][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Name:\\rMUKESH SHARMA\\rAddress:\\rH No 820 Gali ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find={}\n",
    "find[df1.columns[0].split()[0]]=df1.columns[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df1['Name :'])):\n",
    "    if df1['Name :'][i]=='Email :':\n",
    "        find[df1['Name :'][i].split()[0]]=df1['MUKESH SHARMA'][i]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find[df1.columns[4].split()[0]]=df1.columns[4].split()[1].split(':')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabula import read_pdf\n",
    "import json\n",
    "df=read_pdf('/home/am/Downloads/read.pdf', output_format='json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=json.dumps(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import camelot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=camelot.read_pdf('/home/am/Downloads/read.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0].parsing_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.export('foo.json', f='json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0].df[0][0].split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=read_pdf('/home/am/Downloads/read.pdf',area=(1,1,100,400), pages='all',relative_area=True,output_format='json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0]['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data={\"state\":\"Uttarakhand\",\n",
    "       \"City\":\"Haridwar\",\n",
    "       \"AUN\":\"24 Lac\",\n",
    "       \"age\":24,\n",
    "      \"specialization\":\"Mutual Fund\",\n",
    "      'experience':10\n",
    "     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.json', 'w') as json_file:\n",
    "    json.dump(data, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = json.loads(open('/home/am/python/data.json').read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output.json', 'w') as json_file:\n",
    "    json.dump(advisor, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advisor={\n",
    "    \"item\": {\n",
    "        \"advisors\": [\n",
    "            {\n",
    "                \"id\": 1,\n",
    "                \"Name\": \"Mukesh Bhardwaj\",\n",
    "                \"Gender\": \"Male\",\n",
    "                \"city\": \"Rampur\",\n",
    "                \"Experience\": \"7\",\n",
    "                \"state\": \"Uttar Pradesh\"\n",
    "            },\n",
    "            {\n",
    "                \"id\": 2,\n",
    "                \"Name\": \"Aniska Sexsena\",\n",
    "                \"Gender\": \"Female\",\n",
    "                \"city\": \"Haridwar\",\n",
    "                \"Experience\": \"8\",\n",
    "                \"state\": \"Uttarakhand\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(advisor['item'][\"advisors\"])):\n",
    "    for j in advisor['item'][\"advisors\"][i]:\n",
    "        if advisor['item'][\"advisors\"][i]['state']==state and advisor['item'][\"advisors\"][i]['city']==city:\n",
    "            print(advisor['item'][\"advisors\"][i]['Name'])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in advisor['item'][\"advisors\"][0]:\n",
    "    if j=='city':\n",
    "        \n",
    "        print(advisor['item'][\"advisors\"][0]['city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advisor['item'][\"advisors\"][0]['Experience']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state='Uttar Pradesh'\n",
    "city='Rampur'\n",
    "Experience=8\n",
    "ex=[5,6,7,8,9,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(advisor['item'][\"advisors\"])):\n",
    "    if int(advisor['item'][\"advisors\"][i]['Experience']) in ex:\n",
    "        print(advisor['item'][\"advisors\"][i]['Experience'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advisor['item'][\"advisors\"][0]['Experience']  in ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advisor['item'][\"advisors\"][0]['Experience']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advisor={\n",
    "    \"item\": {\n",
    "        \"advisors\": [\n",
    "            {\n",
    "                \"id\": 1,\n",
    "                \"Name\": \"Mukesh Bhardwaj\",\n",
    "                \"Gender\": \"Male\",\n",
    "                \"city\": \"Rampur\",\n",
    "                \"Experience\": \"7\",\n",
    "                \"state\": \"Uttar Pradesh\"\n",
    "            },\n",
    "            {\n",
    "                \"id\": 2,\n",
    "                \"Name\": \"Aniska Sexsena\",\n",
    "                \"Gender\": \"Female\",\n",
    "                \"city\": \"Haridwar\",\n",
    "                \"Experience\": \"8\",\n",
    "                \"state\": \"Uttarakhand\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = {}\n",
    "output_data['advisors'] = []\n",
    "id=1\n",
    "for i in range(len(advisor['item'][\"advisors\"])):\n",
    "    for j in advisor['item'][\"advisors\"][i]:\n",
    "        if int(advisor['item'][\"advisors\"][i]['Experience']) in ex:\n",
    "            data = {}\n",
    "            data['id']=id\n",
    "            data['Name'] = advisor['item'][\"advisors\"][i]['Name']\n",
    "            data['Gender'] = advisor['item'][\"advisors\"][i]['Gender']\n",
    "            data['Experience'] = advisor['item'][\"advisors\"][i]['Experience']\n",
    "            data['State'] = advisor['item'][\"advisors\"][i]['state']\n",
    "            data['city'] = advisor['item'][\"advisors\"][i]['city']\n",
    "            output_data['advisors'].append(data)\n",
    "            id+=1\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['ad'].append({'name':'atul'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myclient = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "mydb = myclient[\"mydatabase\"]\n",
    "mycol = mydb['Advisor_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data in mycol.find():\n",
    "    print('collection data already exists')\n",
    "else:\n",
    "    insrt=mycol.insert_one(advisor)\n",
    "    print('successfully inserted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=mycol.find_one({},{'item':1,'_id':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advisor=mycol.find_one({},{'_id':0})\n",
    "advisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output={}\n",
    "output['item']=[]\n",
    "for i in range(4):\n",
    "    data={}\n",
    "    name,age,ex,state,city=input('enter seperated by (,): ').split(',')\n",
    "    data['name']=name\n",
    "    data['age']=age\n",
    "    data['Expereince']=ex\n",
    "    data['State']=state\n",
    "    data['city']=city\n",
    "    output['item'].append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabula import read_pdf\n",
    "\n",
    "df=read_pdf('/home/am/Downloads/read.pdf',area=(1,1,100,400), pages='all',relative_area=True,output_format='json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "for i in range(len(df[0]['data'])):\n",
    "    for j in range(len(df[0]['data'][i])):\n",
    "        data.append(df[0]['data'][i][j]['text'])\n",
    "        print(df[0]['data'][i][j]['text'].strip(\"   \"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=list(dict.fromkeys(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.remove('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data:\n",
    "    if 'Name' in i or 'Email' in i :\n",
    "        print(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data:\n",
    "    if 'Balance Units' in i:\n",
    "        break\n",
    "\n",
    "    if i=='Unit Balance':\n",
    "        continue\n",
    "    print(i)\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a={ \"item\" : [ { \"id\" : 1, \"name\" : \"Dharmendra Singh\", \"State\" : \"Uttar Paradesh\", \"City\" : \"Moradabad\" }, { \"id\" : 2, \"Name\" : \"Mohd Junaid\", \"State\" : \"Uttar Pradesh\", \"City\" : \"Amroha\" } ] }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['item'][0]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "url=input('Enter URL or Paste here: ')\n",
    "page=requests.get(url).text\n",
    "soup=BeautifulSoup(page,'html.parser')\n",
    "data=soup.find('table',{'class':'fund-snapshot-port-holdings-equity'})\n",
    "table=[]\n",
    "for rows in data.find_all('tr'):\n",
    "    cols=rows.find_all('td')\n",
    "    if len(cols)==7:\n",
    "        dat=[]\n",
    "        table.append(dat)\n",
    "        for i in range(len(cols)):\n",
    "            if i==0:\n",
    "                continue\n",
    "            dat.append(cols[i].text.strip())\n",
    "col_name=[]\n",
    "for th in data.find_all('tr'):\n",
    "    name=th.find_all('th')\n",
    "    if len(name)==7:\n",
    "        for i in range(len(name)):\n",
    "            if i==0:\n",
    "                continue            \n",
    "            col_name.append(name[i].text.strip())\n",
    "    #col.append(name[0].text.strip())\n",
    "#print(col_name)\n",
    "df=pd.DataFrame(table, columns=col_name)\n",
    "df=df.apply(pd.to_numeric ,errors='ignore')\n",
    "file_name=input('Enter File Name To Save: ')\n",
    "df.to_csv(f'{file_name}.csv')\n",
    "#df.info()\n",
    "#df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rows in data.find_all('tr'):\n",
    "    cols=rows.find_all('td')\n",
    "    if len(cols)==7:\n",
    "        for i in range(len(cols)):\n",
    "            if i==0:\n",
    "                continue\n",
    "            print(cols[i].text)\n",
    "                #dat.append(cols[i].text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for th in data.find_all('tr'):\n",
    "    name=th.find_all('th')\n",
    "    if len(name)==7:\n",
    "        \n",
    "        print(name[2].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.valueresearchonline.com/funds/newsnapshot.asp?schemecode=10594&utm_source=direct-click&utm_medium=funds&utm_term=&utm_content=Kotak+Standard+Multicap+Reg&utm_campaign=vro-search'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=url.split('m_content=')\n",
    "b=a[1].split('&utm_campaign=vro-search')\n",
    "c=b[0].replace('+',\" \")\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=a[1].split('&utm_campaign=vro-search')\n",
    "c=b[0].replace('+',\" \")\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url_all='https://www.valueresearchonline.com/funds/fundSelector/default.asp?myport=&amc=4%2C8799%2C5%2C312%2C332%2C8%2C181%2C339%2C8927%2C28%2C302%2C308%2C14%2C9023%2C298%2C9636%2C9655%2C319%2C12232%2C19%2C218%2C185%2C21%2C11141%2C327%2C9054%2C24%2C9055%2C10157%2C15%2C11%2C317%2C186%2C25%2C26%2C187%2C27%2C10%2C9521%2C311%2C12160&cat=equityAll%2CdebtsAll%2ChybridAll%2C100%2C101%2C102%2C103%2C104%2C105%2C106%2C107%2C108%2C109%2C110%2C111%2C112%2C113%2C114%2C115%2C116%2C117%2C118%2C119%2C120%2C121%2C122%2C123%2C124%2C125%2C126%2C127%2C128%2C129%2C130%2C131%2C132%2C133%2C134%2C135%2C136%2C137%2C139%2C140%2C141%2C142%2C143%2C144&exc=&isTabChng=1&pg=#'\n",
    "\n",
    "page=requests.get(url_all).text\n",
    "soup=BeautifulSoup(page,'html.parser')\n",
    "data=soup.find('div',{'class':'pull-left'})\n",
    "links=[]\n",
    "for rows in data.find_all('tr'):\n",
    "    cols=rows.find_all('td')\n",
    "    if len(cols)==9:\n",
    "        for i in cols:\n",
    "            c=i.find('a')\n",
    "            try:\n",
    "                if c.get('href')[0:4]!='/pdf':\n",
    "                    links.append('https://www.valueresearchonline.com'+c.get('href'))\n",
    "            except:\n",
    "\n",
    "                break\n",
    "df=pd.DataFrame(links,columns=['links'])\n",
    "df.to_csv('MutualFundLinks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3952"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' L&T FMP Series XVII Plan C (1114 Days) - Direct Plan'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find Name of Mutual Fund\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = \"https://www.valueresearchonline.com/funds/newsnapshot.asp?schemecode=37631\"\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "#a=soup.title.text\n",
    "#a.split(a[a.index(':'):])[0].rstrip()\n",
    "soup.title.text.split(soup.title.text[soup.title.text.index(':'):])[0].rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('MutualFundLinks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.valueresearchonline.com/funds/newsnapshot.asp?schemecode=4018\n"
     ]
    }
   ],
   "source": [
    "for url in df['links']:\n",
    "    print(url)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter URL or Paste here: https://www.valueresearchonline.com/funds/newsnapshot.asp?schemecode=2882\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "url=input('Enter URL or Paste here: ')\n",
    "page=requests.get(url).text\n",
    "soup=BeautifulSoup(page,'html.parser')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter URL or Paste here: https://www.valueresearchonline.com/funds/newsnapshot.asp?schemecode=4018\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "url=input('Enter URL or Paste here: ')\n",
    "page=requests.get(url).text\n",
    "soup=BeautifulSoup(page,'html.parser')\n",
    "\n",
    "def Hybrid_and_Debt_Data():\n",
    "    data=soup.find('table',{'class':'fund-snapshot-port-holdings-other'})\n",
    "    file_name = soup.title.text.split(soup.title.text[soup.title.text.index(':'):])[0].rstrip()\n",
    "    table=[]\n",
    "    col_name=[]\n",
    "    try:\n",
    "        for rows in data.find_all('tr'):\n",
    "            cols=rows.find_all('td')\n",
    "            if len(cols)>=6:\n",
    "                dat=[]\n",
    "                table.append(dat)\n",
    "                for i in range(len(cols)):\n",
    "                    if i==0:\n",
    "                        continue\n",
    "                    dat.append(cols[i].text.strip())\n",
    "        for th in data.find_all('tr'):\n",
    "            name=th.find_all('th')\n",
    "            if len(name)==6:\n",
    "                for i in range(len(name)):\n",
    "                    if i==0:\n",
    "                        continue            \n",
    "                    col_name.append(name[i].text.strip())\n",
    "    except:\n",
    "        pass\n",
    "    return table, col_name, file_name\n",
    "\n",
    "\n",
    "def EquityData():\n",
    "    data=soup.find('table',{'class':'fund-snapshot-port-holdings-equity'})\n",
    "    file_name = soup.title.text.split(soup.title.text[soup.title.text.index(':'):])[0].rstrip()\n",
    "    table=[]\n",
    "    col_name=[]\n",
    "    try:\n",
    "        for rows in data.find_all('tr'):\n",
    "            cols=rows.find_all('td')\n",
    "            if len(cols)>=6:\n",
    "                dat=[]\n",
    "                table.append(dat)\n",
    "                for i in range(len(cols)):\n",
    "                    if i==0:\n",
    "                        continue\n",
    "                    dat.append(cols[i].text.strip())\n",
    "        for th in data.find_all('tr'):\n",
    "            name=th.find_all('th')\n",
    "            if len(name)==7:\n",
    "                for i in range(len(name)):\n",
    "                    if i==0:\n",
    "                        continue            \n",
    "                    col_name.append(name[i].text.strip())\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    \n",
    "    return table, col_name, file_name\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final():\n",
    "    NoData=[]\n",
    "    hybrid, col_name, file_name = Hybrid_and_Debt_Data()\n",
    "    Equity, col_nameE, file_name= EquityData()   \n",
    "    if len(Equity)>=5 and len(hybrid)>=5:\n",
    "        df=pd.DataFrame(Equity, columns=col_nameE)\n",
    "        df.to_csv(file_name+'Equity.csv')\n",
    "        df1=pd.DataFrame(hybrid, columns=col_name)\n",
    "        df1.to_csv(file_name+'hybrid.csv')\n",
    "    elif len(hybrid)>=5:\n",
    "        df1=pd.DataFrame(hybrid, columns=col_name)\n",
    "        df1.to_csv(file_name+'hybrid.csv')\n",
    "    else:\n",
    "        NoData.append(url)\n",
    "        print(f\"No mutual fund found in {file_name}\")\n",
    "        return NoData\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NoData():\n",
    "    NoData=final()\n",
    "    df=pd.DataFrame(NoData, columns=['No_Data'])\n",
    "    df.to_csv('No_Data_Url.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No mutual fund found in  Aditya Birla Sun Life Active Debt Multi-Manager FoF Scheme\n"
     ]
    }
   ],
   "source": [
    "NoData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=soup.find('table',{'class':'fund-snapshot-port-holdings-other'})\n",
    "col_name=[]\n",
    "for th in data.find_all('tr'):\n",
    "        name=th.find_all('th')\n",
    "        if len(name)==6:\n",
    "            for i in range(len(name)):\n",
    "                if i==0:\n",
    "                    continue            \n",
    "                col_name.append(name[i].text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Company', 'Instrument', 'Credit Rating', '1Y Range', '% Assets']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
